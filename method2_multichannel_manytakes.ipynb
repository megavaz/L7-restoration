{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tifffile import imshow, imsave\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from utils import create_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def NDVI(img):\n",
    "    ndvi = (img[:,:,:,1] - img[:,:,:,0])/(img[:,:,:,0] + img[:,:,:,1] + 1E-6)\n",
    "    return ndvi.reshape(*ndvi.shape[:3])\n",
    "\n",
    "\n",
    "def parse_image(path, all_channels_last=False):\n",
    "  im = np.load(path)\n",
    "  img = im['arr_0']\n",
    "  if all_channels_last:\n",
    "    img = np.moveaxis(img, 0, 2)\n",
    "    img = img.reshape(img.shape[0], img.shape[1], -1)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_intersection(img):\n",
    "    mask = np.ones((955,955), dtype=np.bool)\n",
    "    for i in range(len(img)):\n",
    "        msk = img[i] == 0\n",
    "        mask = mask * msk\n",
    "    return np.count_nonzero(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor\n",
    "from skimage.morphology import dilation, disk\n",
    "from catboost import CatBoostError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_train_data(target_image, training_images, target_mask, train_mask, j, window_size):\n",
    "    target_image_window = target_image[:, j: j + window_size]\n",
    "    target_mask_window = target_mask[:, j: j + window_size]\n",
    "    if np.count_nonzero(target_mask_window) == 0:\n",
    "        return 0, 0, 0, 0, 0\n",
    "    train_mask_window = train_mask[:, j: j + window_size]\n",
    "    training_images_window = training_images[:, :, j: j + window_size]\n",
    "    train_data = np.array([training_images_window[m][train_mask_window] for m in range(len(training_images_window))])\n",
    "    train_label = target_image_window[train_mask_window]\n",
    "    train_data = np.moveaxis(train_data, 0, 1)\n",
    "    mask_to_fill = train_data == 0\n",
    "    train_data[mask_to_fill] = None\n",
    "    restore_data = np.array([training_images_window[m][target_mask_window] for m in range(len(training_images_window))])\n",
    "    restore_data = np.moveaxis(restore_data, 0, 1)\n",
    "    mask_to_fill = restore_data == 0\n",
    "    restore_data[mask_to_fill] = None\n",
    "    return train_data, train_label, restore_data, target_mask_window, target_image_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_order(img):\n",
    "    number_of_skips = [np.count_nonzero(img[i] == 0) for i in range(img.shape[0])]\n",
    "    order = [i for i in range(img.shape[0])]\n",
    "    order = [x for x, _ in sorted(zip(order, number_of_skips), key=lambda pair: pair[1])]\n",
    "    return order\n",
    "\n",
    "def create_horizontal_iteration(img, mask, epsilon=1, n=5, total_max_segments=65, max_covered_length=35):\n",
    "    total_max_segments -= 2\n",
    "    horizontal_iteration = [0]\n",
    "    sliding_average = img[mask][0]\n",
    "    threshold = epsilon * np.std(img[mask])\n",
    "    for j in range(0, img.shape[-1]):\n",
    "        current_value = img[:, j][mask[:,j]]\n",
    "        if current_value.size == 0:\n",
    "            continue\n",
    "        current_value = np.average(current_value)\n",
    "        if np.abs(sliding_average - current_value) >= threshold:\n",
    "            horizontal_iteration.append(j)\n",
    "            sliding_average = current_value\n",
    "        else:\n",
    "            sliding_average = (sliding_average * (n - 1) + current_value) / n\n",
    "        if j - horizontal_iteration[-1] == max_covered_length:\n",
    "            horizontal_iteration.append(j)\n",
    "    # print(total_max_segments, len(horizontal_iteration))\n",
    "    try:\n",
    "        ratio = len(horizontal_iteration) / total_max_segments\n",
    "    except ZeroDivisionError:\n",
    "        return [0, 955]\n",
    "    if ratio > 1:\n",
    "        horizontal_iteration_temp = [0]\n",
    "        main_number, lagging_number = 0, 0\n",
    "        for elem in horizontal_iteration:\n",
    "            main_number += 1\n",
    "            if main_number // ratio > lagging_number:\n",
    "                lagging_number += 1\n",
    "                horizontal_iteration_temp.append(elem)\n",
    "        horizontal_iteration = horizontal_iteration_temp\n",
    "    horizontal_iteration.append(img.shape[-1])\n",
    "    return horizontal_iteration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# range_object = create_order(img_volume)\n",
    "# range_object = range_object[3:4]\n",
    "# for i in range_object:\n",
    "#     imshow(img_volume[i,:,:,0], vmax=1, vmin=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from tensorflow.estimator import BoostedTreesRegressor\n",
    "def restore_images(img_volume, restoration_order, epsilon = 0.72, max_length = 36, total_max_segments = 52, NDVI_format=False):\n",
    "    model = CatBoostRegressor(\n",
    "        learning_rate=0.2,\n",
    "        depth=3,\n",
    "        loss_function='RMSE',\n",
    "        verbose=0,\n",
    "        num_trees=65\n",
    "    )\n",
    "    img_volume_ndvi = NDVI(img_volume)\n",
    "    for target_image_number in restoration_order:\n",
    "        target_image = img_volume[target_image_number]\n",
    "        target_image_v = img_volume_ndvi[target_image_number]\n",
    "        # if np.abs(np.mean(target_image_v[target_image[:,:,0] != 0])) < 0.02:\n",
    "        #     model = CatBoostRegressor(\n",
    "        #         learning_rate=0.2,\n",
    "        #         depth=10,\n",
    "        #         loss_function='RMSE',\n",
    "        #         verbose=0,\n",
    "        #         num_trees=20\n",
    "        #     )\n",
    "        #     print('a')\n",
    "        # else:\n",
    "        #     model = CatBoostRegressor(\n",
    "        #         learning_rate=0.2,\n",
    "        #         depth=3,\n",
    "        #         loss_function='RMSE',\n",
    "        #         verbose=0,\n",
    "        #         num_trees=65\n",
    "        #     )\n",
    "        #     print('b')\n",
    "\n",
    "        complementary_mask = target_image[:,:,0] != 0\n",
    "        target_mask = create_mask(target_image)\n",
    "        train_mask = dilation(target_mask, disk(1))\n",
    "        # train_mask = train_mask ^ target_mask\n",
    "        restore_indexes = np.where(train_mask)\n",
    "        indexes = np.moveaxis(np.array(restore_indexes), 0, 1)\n",
    "        labels = DBSCAN(eps=1.5).fit_predict(indexes)\n",
    "        train_masks = []\n",
    "        target_masks = []\n",
    "        for i in set(labels):\n",
    "            ind = np.where(labels == i)\n",
    "            train_mask_2 = np.zeros(shape=train_mask.shape, dtype=np.bool)\n",
    "            rst = tuple((restore_indexes[0][ind], restore_indexes[1][ind]))\n",
    "            train_mask_2[rst] = True\n",
    "            target_masks.append(train_mask_2 * target_mask)\n",
    "            train_masks.append((train_mask_2 ^ target_masks[-1]) * complementary_mask)\n",
    "        # print(len(set(labels)))\n",
    "        # break\n",
    "        # train_mask = target_image != 0\n",
    "        # imshow(target_mask)\n",
    "        # break\n",
    "        # train_masks = [train_masks[l] + train_masks[l+1] for l in range(0, len(train_masks), 2)]\n",
    "        # target_masks = [target_masks[l] + target_masks[l+1] for l in range(0, len(target_masks), 2)]\n",
    "        check_mask = []\n",
    "        # max_area = np.max(np.count_nonzero(target_masks, axis=(1,2)))\n",
    "        lengths = []\n",
    "        for _ in range(len(target_masks)):\n",
    "            auxilary = np.where(target_masks[_])[1]\n",
    "            lengths.append(auxilary[-1] - auxilary[0])\n",
    "        max_area = target_masks[0].shape[-1]\n",
    "        # print(lengths)\n",
    "        if NDVI_format:\n",
    "            training_images = np.concatenate([img_volume_ndvi[:target_image_number], img_volume_ndvi[target_image_number+1:]], axis=0)\n",
    "            training_images = np.expand_dims(training_images, -1)\n",
    "            target_image = np.expand_dims(target_image_v, -1)\n",
    "        else:\n",
    "            training_images = np.concatenate([img_volume[:target_image_number], img_volume[target_image_number+1:]], axis=0)\n",
    "        for train_mask_current, target_mask_current, current_area in tqdm(zip(train_masks, target_masks, lengths), total=len(target_masks)):\n",
    "            # current_area = np.count_nonzero(target_mask_current)\n",
    "            # print(current_area, max_area)\n",
    "\n",
    "            horizontal_iteration = create_horizontal_iteration(\n",
    "                target_image[:,:,0],\n",
    "                train_mask_current,\n",
    "                epsilon=epsilon,\n",
    "                n=1, total_max_segments=int(np.round(total_max_segments * current_area / max_area + 1)),\n",
    "                max_covered_length=max_length\n",
    "            )\n",
    "            aux = np.array(target_mask_current)\n",
    "            try:\n",
    "                aux[:, horizontal_iteration[:-1]] = False\n",
    "            except:\n",
    "                aux[:, horizontal_iteration[:-2]] = False\n",
    "            check_mask.append(target_mask_current ^ aux)\n",
    "        # return check_mask\n",
    "        #     print(len(horizontal_iteration))\n",
    "\n",
    "            for m in range(len(horizontal_iteration) - 1):\n",
    "                for channel in range(1 if NDVI_format else 2):\n",
    "                    successful = False\n",
    "                    disc_size = 1\n",
    "                    while not successful:\n",
    "                        j = horizontal_iteration[m]\n",
    "                        window_size = horizontal_iteration[m+1] - j\n",
    "                        train_data, train_label, restore_data,\\\n",
    "                        target_mask_window, target_image_window = create_train_data(\n",
    "                            target_image[:,:,channel],\n",
    "                            training_images[:,:,:,channel],\n",
    "                            target_mask_current,\n",
    "                            train_mask_current,\n",
    "                            j, window_size\n",
    "                        )\n",
    "                        if type(train_data) == int:\n",
    "                            # print('err0')\n",
    "                            successful = True\n",
    "                            continue\n",
    "                        # print(train_data.shape)\n",
    "                        # imshow(target_mask_window)\n",
    "                        # imshow(target_image_window)\n",
    "                        # print(train_data, '|', train_label)\n",
    "                        train_pool = Pool(train_data, train_label)\n",
    "\n",
    "\n",
    "                        # tick = time()\n",
    "                        try:\n",
    "                            model.fit(train_pool)\n",
    "                            restore_pool = Pool(restore_data)\n",
    "                            res = model.predict(restore_pool)\n",
    "                            successful = True\n",
    "                        except CatBoostError:\n",
    "                            # print('Err1')\n",
    "                            # train_mask_current[:, j:j+window_size] = \\\n",
    "                            #     dilation(\n",
    "                            #         train_mask_current[:, j:j+window_size],\n",
    "                            #         disk(disc_size)\n",
    "                            #     ) ^ target_mask_current[:, j:j+window_size]\n",
    "                            # disc_size += 1\n",
    "                            # continue\n",
    "                            res = np.full((restore_data.shape[0],), np.average(train_label[0]))\n",
    "                            successful = True\n",
    "                        # tack = time()\n",
    "                        # print((tack - tick) * 1000)\n",
    "                        # break\n",
    "                        target_image_window[target_mask_window] = res\n",
    "                        if NDVI_format:\n",
    "                            img_volume_ndvi[target_image_number, :, j: j + window_size] = target_image_window\n",
    "                        else:\n",
    "                            img_volume[target_image_number, :, j: j + window_size, channel] = target_image_window\n",
    "            # break\n",
    "    if NDVI_format:\n",
    "        return np.clip(img_volume_ndvi, -1, 1)\n",
    "    img_volume = np.clip(img_volume, 0, 1)\n",
    "    return img_volume"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for img_num in range(3, 4):\n",
    "    path = 'D:/Docs/Visillect/agrofields/adc/restoration/data/extended/input/L8_{}.npz'.format(img_num)\n",
    "    img_volume = parse_image(path)\n",
    "    range_object = create_order(img_volume)\n",
    "    # for target_image_number in range_object:\n",
    "    #     print(np.mean(NDVI(img_volume)[target_image_number][img_volume[target_image_number, :, :, 0] != 0]))\n",
    "    # img_volume = NDVI(img_volume)\n",
    "    if check_intersection(img_volume[:,:,:,0]) != 0:\n",
    "        continue\n",
    "    # img_volume = restore_images(img_volume, restoration_order=[1], total_max_segments=52, epsilon=0.72)\n",
    "    img_volume = restore_images(img_volume, restoration_order=range_object, total_max_segments=65, epsilon=0.7, NDVI_format=True)\n",
    "    # np.savez('D:/Docs/Visillect/agrofields/adc/restoration/data/extended/results/L8_{}.npz'.format(img_num), img_volume)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# megamask = np.zeros((955, 955), np.bool)\n",
    "# for msk in mask:\n",
    "#     megamask = megamask ^ msk\n",
    "# imshow(megamask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# img_num = 0\n",
    "path = 'D:/Docs/Visillect/agrofields/adc/restoration/data/extended/output/L8_{}.npz'.format(img_num)\n",
    "\n",
    "img2 = parse_image(path)\n",
    "# img2 = img2[:,:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# img3 = np.array(img2)\n",
    "# img3[2, :, :, 0][megamask] = 0\n",
    "# # imshow(img3[1, :, :, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from hyperopt import hp, tpe, fmin\n",
    "from copy import deepcopy\n",
    "# \n",
    "# def objective_wrapper(im_num, img_volume, img2):\n",
    "#     def objective(params):\n",
    "#         test = deepcopy(img_volume)\n",
    "#         true = img2\n",
    "#         test_num = im_num\n",
    "#         test = restore_images(test, [test_num], **params)\n",
    "#         score = mean_absolute_error(test[test_num,:,:,0].reshape(-1), true[test_num,:,:,0].reshape(-1))\n",
    "#         print(score)\n",
    "#         return score\n",
    "#     return objective\n",
    "# \n",
    "# space = {\n",
    "#     'epsilon':hp.quniform('epsilon', 0.65, 0.8, 0.01),\n",
    "#     'max_length':hp.quniform('max_length', 28, 40, 3),\n",
    "#     'total_max_segments':hp.quniform('total_max_segments', 36, 64, 4)\n",
    "# }\n",
    "# \n",
    "# best = fmin(objective_wrapper(4, img_volume, img2), space, algo=tpe.suggest, max_evals=32)\n",
    "# print(best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# img_volume = np.clip(img_volume, 0, 1)\n",
    "# chnl = 0\n",
    "# for i in range(10):\n",
    "#     imshow(img_volume[i,:,:,chnl], vmax=1, vmin=0)\n",
    "#     # imshow(img3[i,:,:,chnl], vmax=1, vmin=0)\n",
    "#     imshow(img2[i,:,:,chnl], vmax=1, vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# for target_image_number in range(img_volume.shape[0]):\n",
    "#     print(mean_absolute_error(img2[target_image_number].reshape(-1), img_volume[target_image_number].reshape(-1)))\n",
    "    # print(mean_squared_error(img2[target_image_number, :, :, 0].reshape(-1), img[target_image_number].reshape(-1)) ** (1 / 2))\n",
    "    # imsave('res{}.tif'.format(target_image_number), img[target_image_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# VI_restored = NDVI(img_volume)\n",
    "VI_restored = img_volume\n",
    "VI_good = NDVI(img2)\n",
    "print(img_volume.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for target_image_number in range(10):\n",
    "    print(mean_absolute_error(VI_good[target_image_number].reshape(-1), VI_restored[target_image_number, :, :].reshape(-1)))\n",
    "    imshow(VI_restored[target_image_number, :, :], vmin=-0.5, vmax=0.5)\n",
    "    imshow(VI_good[target_image_number], vmin=-0.5, vmax=0.5)\n",
    "    # imsave('res{}.tif'.format(target_image_number), VI_restored[target_image_number])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VISI",
   "language": "python",
   "name": "visillect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}