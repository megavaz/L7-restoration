{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from tifffile import imshow, imsave\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from utils import create_mask\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostError\n",
    "from skimage.morphology import dilation, disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def NDVI(img, last_channel=False):\n",
    "    ndvi = (img[:,:,:,1] - img[:,:,:,0])/(img[:,:,:,1] + img[:,:,:,0] + 1E-6)\n",
    "    if last_channel:\n",
    "        return np.expand_dims(ndvi, -1)\n",
    "    return ndvi\n",
    "\n",
    "\n",
    "def parse_image(path, all_channels_last=False):\n",
    "  im = np.load(path)\n",
    "  img = im['arr_0']\n",
    "  if all_channels_last:\n",
    "    img = np.moveaxis(img, 0, 2)\n",
    "    img = img.reshape(img.shape[0], img.shape[1], -1)\n",
    "  return img\n",
    "\n",
    "\n",
    "def check_intersection(img):\n",
    "    mask = np.ones((955,955), dtype=bool)\n",
    "    for i in range(len(img)):\n",
    "        msk = img[i] == 0\n",
    "        mask = mask * msk\n",
    "    return np.count_nonzero(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_train_data(target_image, training_images, target_mask, train_mask, j, window_size, geospatial=True):\n",
    "    target_image_window = target_image[:, j: j + window_size]\n",
    "    target_mask_window = target_mask[:, j: j + window_size]\n",
    "    if np.count_nonzero(target_mask_window) == 0:\n",
    "        return 0, 0, 0, 0, 0\n",
    "    train_mask_window = train_mask[:, j: j + window_size]\n",
    "    training_images_window = training_images[:, :, j: j + window_size]\n",
    "    train_data = np.array([training_images_window[m][train_mask_window] for m in range(len(training_images_window))])\n",
    "    train_label = target_image_window[train_mask_window]\n",
    "    train_data = np.moveaxis(train_data, 0, 1)\n",
    "    if geospatial:\n",
    "        coordinates = np.array(np.where(train_mask_window))\n",
    "        coordinates = np.moveaxis(coordinates, 0, 1)\n",
    "        train_data = np.concatenate([train_data, coordinates], axis=1)\n",
    "    restore_data = np.array([training_images_window[m][target_mask_window] for m in range(len(training_images_window))])\n",
    "    restore_data = np.moveaxis(restore_data, 0, 1)\n",
    "    if geospatial:\n",
    "        coordinates = np.array(np.where(target_mask_window))\n",
    "        coordinates = np.moveaxis(coordinates, 0, 1)\n",
    "        restore_data = np.concatenate([restore_data, coordinates], axis=1)\n",
    "    return train_data, train_label, restore_data, target_mask_window, target_image_window\n",
    "\n",
    "def create_train_data_quick(target_image, training_images, target_mask, train_mask, i, j, window_size, geospatial=True):\n",
    "    target_image_window = target_image[i: i + window_size, j: j + window_size]\n",
    "    target_mask_window = target_mask[i: i + window_size, j: j + window_size]\n",
    "    if np.count_nonzero(target_mask_window) == 0:\n",
    "        return 0, 0, 0, 0, 0\n",
    "    train_mask_window = train_mask[i: i + window_size, j: j + window_size]\n",
    "    training_images_window = training_images[:, i: i + window_size, j: j + window_size]\n",
    "    train_data = np.array([training_images_window[m][train_mask_window] for m in range(len(training_images_window))])\n",
    "    train_label = target_image_window[train_mask_window]\n",
    "    train_data = np.moveaxis(train_data, 0, 1)\n",
    "    if geospatial:\n",
    "        coordinates = np.array(np.where(train_mask_window))\n",
    "        coordinates = np.moveaxis(coordinates, 0, 1)\n",
    "        train_data = np.concatenate([train_data, coordinates], axis=1)\n",
    "    restore_data = np.array([training_images_window[m][target_mask_window] for m in range(len(training_images_window))])\n",
    "    restore_data = np.moveaxis(restore_data, 0, 1)\n",
    "    if geospatial:\n",
    "        coordinates = np.array(np.where(target_mask_window))\n",
    "        coordinates = np.moveaxis(coordinates, 0, 1)\n",
    "        restore_data = np.concatenate([restore_data, coordinates], axis=1)\n",
    "    return train_data, train_label, restore_data, target_mask_window, target_image_window\n",
    "\n",
    "\n",
    "def create_order(img):\n",
    "    number_of_skips = [np.count_nonzero(img[i] == 0) for i in range(img.shape[0])]\n",
    "    order = [i for i in range(img.shape[0])]\n",
    "    order = [x for x, _ in sorted(zip(order, number_of_skips), key=lambda pair: pair[1])]\n",
    "    return order\n",
    "\n",
    "def create_horizontal_iteration(img, mask, epsilon=1, n=5, total_max_segments=65, max_covered_length=35):\n",
    "    total_max_segments -= 2\n",
    "    horizontal_iteration = [0]\n",
    "    sliding_average = img[mask][0]\n",
    "    threshold = epsilon * np.std(img[mask])\n",
    "    for j in range(0, img.shape[-1]):\n",
    "        current_value = img[:, j][mask[:,j]]\n",
    "        if current_value.size == 0:\n",
    "            continue\n",
    "        current_value = np.average(current_value)\n",
    "        if np.abs(sliding_average - current_value) >= threshold:\n",
    "            horizontal_iteration.append(j)\n",
    "            sliding_average = current_value\n",
    "        else:\n",
    "            sliding_average = (sliding_average * (n - 1) + current_value) / n\n",
    "        if j - horizontal_iteration[-1] == max_covered_length:\n",
    "            horizontal_iteration.append(j)\n",
    "    # print(total_max_segments, len(horizontal_iteration))\n",
    "    try:\n",
    "        ratio = len(horizontal_iteration) / total_max_segments\n",
    "    except ZeroDivisionError:\n",
    "        return [0, 955]\n",
    "    if ratio > 1:\n",
    "        horizontal_iteration_temp = [0]\n",
    "        main_number, lagging_number = 0, 0\n",
    "        for elem in horizontal_iteration:\n",
    "            main_number += 1\n",
    "            if main_number // ratio > lagging_number:\n",
    "                lagging_number += 1\n",
    "                horizontal_iteration_temp.append(elem)\n",
    "        horizontal_iteration = horizontal_iteration_temp\n",
    "    horizontal_iteration.append(img.shape[-1])\n",
    "    return horizontal_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dummy_restore(img_volume, mask_volume):\n",
    "    def roll_down(mask, i):\n",
    "        for m in range(i, i + 30):\n",
    "            if not mask[m]:\n",
    "                return m\n",
    "            return m\n",
    "\n",
    "    for channel in range(img_volume.shape[3]):\n",
    "        mask = img_volume[:,:,:,channel] == 0\n",
    "        mask = mask * mask_volume\n",
    "        if np.count_nonzero(mask) != 0:\n",
    "            indexes = np.where(mask)\n",
    "            (numbers, i_s, j_s) = indexes\n",
    "            for number, i, j in zip(numbers.tolist(), i_s.tolist(), j_s.tolist()):\n",
    "                img_volume[number, i, j, channel] = img_volume[number, i - 1, j, channel] if i - 1 > 0 else img_volume[number, roll_down(mask_volume[number, :, j], i), j, channel]\n",
    "    return img_volume\n",
    "\n",
    "# def dummy_restore_2(img_volume, mask_volume):\n",
    "#     for channel in range(img_volume.shape[3]):\n",
    "#         if np.count_nonzero(mask_volume) != 0:\n",
    "#             indexes = np.where(np.rot90(mask_volume, axes=(1,2)))\n",
    "#             (numbers, j_s, i_s) = indexes\n",
    "#             for number in range(len(mask_volume)):\n",
    "#                 i_s_sup = i_s[numbers == number]\n",
    "#                 j_s_sup = j_s[numbers == number]\n",
    "#                 for j in range(mask_volume.shape[2]):\n",
    "#                     i_s_sup_sup = i_s_sup[j_s_sup == mask_volume.shape[2] - j - 1]\n",
    "#                     to_restore = []\n",
    "#                     i1 = None\n",
    "#                     for i in range(len(i_s_sup_sup) - 1):\n",
    "#                         if i1 is None:\n",
    "#                             i1 = i_s_sup_sup[i] - 1\n",
    "#                             continue\n",
    "#                         if i_s_sup_sup[i + 1] - i_s_sup_sup[i] > 1:\n",
    "#                             to_restore.append([i1, i_s_sup_sup[i] + 1])\n",
    "#                             i1 = None\n",
    "#                     if not i1 is None:\n",
    "#                         to_restore.append([i1, i_s_sup_sup[-1] + 1])\n",
    "#\n",
    "#                     for edges in to_restore:\n",
    "#                         if edges[1] - edges[0] > 30:\n",
    "#                             continue\n",
    "#                         img_volume[number, edges[0] + 1: edges[1], j, channel] = (img_volume[number, edges[0], j, channel] if edges[0] != -1 else img_volume[number, edges[1], j, channel] + img_volume[number, edges[1], j, channel] if edges[1] <= img_volume.shape[1] else img_volume[number, edges[0], j, channel] ) / 2\n",
    "#             return img_volume\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def quick_restore(\n",
    "        img_volume,\n",
    "        mask_volume,\n",
    "        restoration_order,\n",
    "        window_size=479,\n",
    "        min_value=0.,\n",
    "        max_value=1.,\n",
    "        verbose=True,\n",
    "        geospatial=True\n",
    "):\n",
    "    try:\n",
    "        assert img_volume.shape[0] == mask_volume.shape[0]\n",
    "    except AssertionError:\n",
    "        print('First dimensions of img_volume and mask_volume must be equal!')\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        learning_rate=0.2,\n",
    "        depth=5,\n",
    "        loss_function='RMSE',\n",
    "        verbose=0,\n",
    "        num_trees=300\n",
    "\n",
    "    )\n",
    "\n",
    "    for target_image_number in restoration_order:\n",
    "        target_image = img_volume[target_image_number]\n",
    "        target_mask = mask_volume[target_image_number]\n",
    "        if np.count_nonzero(target_mask) == 0:\n",
    "            continue\n",
    "        train_mask = dilation(target_mask, disk(1))\n",
    "        train_mask = train_mask ^ target_mask\n",
    "        training_images = np.concatenate([img_volume[:target_image_number], img_volume[target_image_number+1:]], axis=0)\n",
    "        threshold = (target_image.shape[0] - window_size, target_image.shape[1] - window_size)\n",
    "        for i in tqdm(range(0, target_image.shape[0], window_size), disable=not verbose):\n",
    "            for j in range(0, target_image.shape[1], window_size):\n",
    "                if i > threshold[0]:\n",
    "                    i = threshold[0]\n",
    "                if j > threshold[1]:\n",
    "                    j = threshold[1]\n",
    "                for channel in range(img_volume.shape[-1]):\n",
    "                    train_data, train_label, restore_data,\\\n",
    "                    target_mask_window, target_image_window = create_train_data_quick(\n",
    "                        target_image[:,:,channel],\n",
    "                        training_images[:,:,:,channel],\n",
    "                        target_mask,\n",
    "                        train_mask, i, j,\n",
    "                        window_size, geospatial=geospatial\n",
    "                    )\n",
    "                    if type(train_data) == int:\n",
    "                        continue\n",
    "                    train_pool = Pool(train_data, train_label)\n",
    "                    try:\n",
    "                        model.fit(train_pool)\n",
    "                        restore_pool = Pool(restore_data)\n",
    "                        res = model.predict(restore_pool)\n",
    "                    except CatBoostError:\n",
    "                        res = np.full((restore_data.shape[0],), np.average(train_label[0]))\n",
    "                    target_image_window[target_mask_window] = res\n",
    "                    img_volume[target_image_number, i:i + window_size, j: j + window_size, channel] = target_image_window\n",
    "    img_volume = np.nan_to_num(img_volume, nan=0.0)\n",
    "    img_volume = np.clip(img_volume, min_value, max_value)\n",
    "    return img_volume\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def restore_images(\n",
    "        img_volume,\n",
    "        mask_volume,\n",
    "        restoration_order,\n",
    "        epsilon=0.8,\n",
    "        max_length=150,\n",
    "        masks_to_sum=1,\n",
    "        average_segment_length = 318,\n",
    "        min_value=0.,\n",
    "        max_value=1.,\n",
    "        verbose=True,\n",
    "        geospatial=True\n",
    "):\n",
    "\n",
    "    try:\n",
    "        assert img_volume.shape[0] == mask_volume.shape[0]\n",
    "    except AssertionError:\n",
    "        print('First dimensions of img_volume and mask_volume must be equal!')\n",
    "    # for channel in range(img_volume.shape[-1]):\n",
    "    #     img_volume[:,:,:,channel][~mask_volume] = None\n",
    "    # a = img_volume == None\n",
    "    # for i in range(len(a)):\n",
    "    #     imshow(a[i])\n",
    "    # return img_volume\n",
    "    total_max_segments = int(img_volume.shape[1] // average_segment_length)\n",
    "    model = CatBoostRegressor(\n",
    "        learning_rate=0.2,\n",
    "        depth=4,\n",
    "        loss_function='RMSE',\n",
    "        verbose=0,\n",
    "        num_trees=210\n",
    "\n",
    "    )\n",
    "    for target_image_number in restoration_order:\n",
    "        target_image = img_volume[target_image_number]\n",
    "        # complementary_mask = mask_volume_2[target_image_number]\n",
    "        # target_mask = create_mask(complementary_mask)\n",
    "        target_mask = mask_volume[target_image_number]\n",
    "        if np.count_nonzero(target_mask) == 0:\n",
    "            continue\n",
    "        train_mask = dilation(target_mask, disk(1))\n",
    "        restore_indexes = np.where(train_mask)\n",
    "        indexes = np.moveaxis(np.array(restore_indexes), 0, 1)\n",
    "        labels = DBSCAN(eps=1.5).fit_predict(indexes)\n",
    "        train_masks = []\n",
    "        target_masks = []\n",
    "        for i in set(labels):\n",
    "            ind = np.where(labels == i)\n",
    "            train_mask_2 = np.zeros(shape=train_mask.shape, dtype=bool)\n",
    "            rst = tuple((restore_indexes[0][ind], restore_indexes[1][ind]))\n",
    "            train_mask_2[rst] = True\n",
    "            target_masks.append(train_mask_2 * target_mask)\n",
    "            train_masks.append((train_mask_2 ^ target_masks[-1]) * ~target_mask)\n",
    "        check_mask = []\n",
    "        # max_area = np.max(np.count_nonzero(target_masks, axis=(1,2)))\n",
    "        lengths = []\n",
    "\n",
    "        max_area = target_masks[0].shape[-1]\n",
    "        train_masks_aux = [np.zeros(train_masks[0].shape, dtype=bool)]\n",
    "        target_masks_aux = [np.zeros(train_masks[0].shape, dtype=bool)]\n",
    "        i = 0\n",
    "        for train_mask, target_mask in zip(train_masks, target_masks):\n",
    "            if i < masks_to_sum:\n",
    "                train_masks_aux[-1] = train_masks_aux[-1] + train_mask\n",
    "                target_masks_aux[-1] = target_masks_aux[-1] + target_mask\n",
    "                i += 1\n",
    "            else:\n",
    "                i = 1\n",
    "                train_masks_aux.append(train_mask)\n",
    "                target_masks_aux.append(target_mask)\n",
    "        train_masks = train_masks_aux\n",
    "        target_masks = target_masks_aux\n",
    "        for _ in range(len(target_masks)):\n",
    "            auxiliary = np.where(target_masks[_])[1]\n",
    "            lengths.append(auxiliary[-1] - auxiliary[0])\n",
    "        # train_masks\n",
    "        # print(lengths)\n",
    "        training_images = np.concatenate([img_volume[:target_image_number], img_volume[target_image_number+1:]], axis=0)\n",
    "        for train_mask_current, target_mask_current, current_area in tqdm(zip(train_masks, target_masks, lengths), total=len(target_masks), disable=not verbose):\n",
    "            # current_area = np.count_nonzero(target_mask_current)\n",
    "            # print(current_area, max_area)\n",
    "\n",
    "            horizontal_iteration = create_horizontal_iteration(\n",
    "                target_image[:,:,0],\n",
    "                train_mask_current,\n",
    "                epsilon=epsilon,\n",
    "                n=1,\n",
    "                total_max_segments=int(np.round(total_max_segments * current_area / max_area + 1)),\n",
    "                max_covered_length=max_length\n",
    "            )\n",
    "            # horizontal_iteration = [i for i in range(955)]\n",
    "            # aux = np.array(target_mask_current)\n",
    "            # try:\n",
    "            #     aux[:, horizontal_iteration[:-1]] = False\n",
    "            # except:\n",
    "            #     aux[:, horizontal_iteration[:-2]] = False\n",
    "            # check_mask.append(target_mask_current ^ aux)\n",
    "        # return check_mask\n",
    "        #     print(len(horizontal_iteration))\n",
    "\n",
    "            for m in range(len(horizontal_iteration) - 1):\n",
    "                for channel in range(img_volume.shape[-1]):\n",
    "                    j = horizontal_iteration[m]\n",
    "                    window_size = horizontal_iteration[m+1] - j\n",
    "                    train_data, train_label, restore_data,\\\n",
    "                    target_mask_window, target_image_window = create_train_data(\n",
    "                        target_image[:,:,channel],\n",
    "                        training_images[:,:,:,channel],\n",
    "                        target_mask_current,\n",
    "                        train_mask_current,\n",
    "                        j, window_size, geospatial=geospatial\n",
    "                    )\n",
    "                    if type(train_data) == int:\n",
    "                        # print('err0')\n",
    "                        continue\n",
    "                    train_pool = Pool(train_data, train_label)\n",
    "                    # tick = time()\n",
    "                    try:\n",
    "                        model.fit(train_pool)\n",
    "                        restore_pool = Pool(restore_data)\n",
    "                        res = model.predict(restore_pool)\n",
    "                    except CatBoostError:\n",
    "                        # print('Err1')\n",
    "                        res = np.full((restore_data.shape[0],), np.average(train_label[0]))\n",
    "                    # tack = time()\n",
    "                    # print((tack - tick) * 1000)\n",
    "                    # break\n",
    "                    target_image_window[target_mask_window] = res\n",
    "                    img_volume[target_image_number, :, j: j + window_size, channel] = target_image_window\n",
    "    img_volume = np.nan_to_num(img_volume, nan=0.0)\n",
    "    img_volume = np.clip(img_volume, min_value, max_value)\n",
    "    return img_volume"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "not_full_restoration = False\n",
    "for img_num in tqdm(range(0, 28), disable=False):\n",
    "    path = 'D:/Docs/Visillect/agrofields/adc/restoration/data/extended/input/L8_{}.npz'.format(img_num)\n",
    "    img_volume = parse_image(path)\n",
    "    tick1 = time()\n",
    "    mask_volume = img_volume[:,:,:,0] != 0\n",
    "    range_object = create_order(img_volume)\n",
    "    if check_intersection(img_volume[:,:,:,0]) != 0:\n",
    "        continue\n",
    "    # for target_image_number in range_object:\n",
    "    #     print(np.mean(NDVI(img_volume)[target_image_number][img_volume[target_image_number, :, :, 0] != 0]))\n",
    "    # mask_aux = img_volume[:,:,:,0] == 0\n",
    "    img_volume = NDVI(img_volume, last_channel=True)\n",
    "    for i in range(len(mask_volume)):\n",
    "        mask_volume[i] = create_mask(mask_volume[i])\n",
    "    # imshow(mask_aux[0, :50, :10])\n",
    "    # img_volume = dummy_restore_2(img_volume, mask_aux)\n",
    "    # print(np.count_nonzero(a == 12))\n",
    "    img_volume = dummy_restore(img_volume, mask_volume)\n",
    "    tick2 = time()\n",
    "    img_volume = quick_restore(\n",
    "        img_volume,\n",
    "        mask_volume,\n",
    "        range_object,\n",
    "        min_value=-1.,\n",
    "        verbose=not_full_restoration\n",
    "    )\n",
    "    np.savez('D:/Docs/Visillect/agrofields/adc/restoration/data/extended/results_ndvi_2_quick/L8_{}.npz'.format(img_num), img_volume)\n",
    "    tick3 = time()\n",
    "    img_volume = restore_images(\n",
    "        img_volume,\n",
    "        mask_volume,\n",
    "        restoration_order=range_object,\n",
    "        min_value=-1.,\n",
    "        verbose=not_full_restoration\n",
    "    )\n",
    "    tick4 = time()\n",
    "    print('{:.1f} seconds total, {:.1f} seconds full restoration, {:.1f} seconds quick restoration'.format(tick4 - tick1, tick4 - tick2, tick3 - tick2))\n",
    "    np.savez('D:/Docs/Visillect/agrofields/adc/restoration/data/extended/results_ndvi_2/L8_{}.npz'.format(img_num), img_volume)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# megamask = np.zeros((955, 955), bool)\n",
    "# for msk in mask:\n",
    "#     megamask = megamask ^ msk\n",
    "# imshow(megamask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# img_num = 0\n",
    "path = 'D:/Docs/Visillect/agrofields/adc/restoration/data/extended/output/L8_{}.npz'.format(img_num)\n",
    "\n",
    "img2 = parse_image(path)\n",
    "# img2 = img2[:,:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# img3 = np.array(img2)\n",
    "# img3[2, :, :, 0][megamask] = 0\n",
    "# # imshow(img3[1, :, :, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# img_volume = np.clip(img_volume, 0, 1)\n",
    "# chnl = 0\n",
    "# for i in range(10):\n",
    "#     imshow(img_volume[i,:,:,chnl], vmax=1, vmin=0)\n",
    "#     # imshow(img3[i,:,:,chnl], vmax=1, vmin=0)\n",
    "#     imshow(img2[i,:,:,chnl], vmax=1, vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for target_image_number in range(img_volume.shape[0]):\n",
    "#     print(mean_absolute_error(img2[target_image_number].reshape(-1), img_volume[target_image_number].reshape(-1)))\n",
    "#     print(mean_squared_error(img2[target_image_number, :, :, 0].reshape(-1), img_volume[target_image_number].reshape(-1)) ** (1 / 2))\n",
    "#     # imsave('res{}.tif'.format(target_image_number), img_volume[target_image_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# VI_restored = NDVI(img_volume, last_channel=True)\n",
    "VI_restored = img_volume\n",
    "VI_good = NDVI(img2)\n",
    "print(img_volume.shape, range_object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for target_image_number in range(0, 10):\n",
    "    print(mean_absolute_error(VI_good[target_image_number].reshape(-1), VI_restored[target_image_number, :, :].reshape(-1)))\n",
    "    # print(r2_score(VI_good[target_image_number].reshape(-1), VI_restored[target_image_number, :, :].reshape(-1)))\n",
    "    imshow(VI_restored[target_image_number, :, :, 0], vmin=-0.5, vmax=0.5)\n",
    "    imshow(VI_good[target_image_number], vmin=-0.5, vmax=0.5)\n",
    "    # imsave('res{}.tif'.format(target_image_number), VI_restored[target_image_number])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mask1 = VI_restored[0, 739:769, 750:780, 0] == 0\n",
    "# mask2 = dilation(mask1, disk(3))\n",
    "# mask2 = mask1 ^ mask2\n",
    "# visualization = np.zeros(mask1.shape)\n",
    "# visualization[mask1] = 1\n",
    "# visualization[mask2] = 0.5\n",
    "# imshow(visualization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mask1 = VI_restored[0, :200, 700:900, 0] == 0\n",
    "# aux = VI_restored[0, :200, 700:900, 0]\n",
    "# mask2 = ~mask1\n",
    "# mask2 = create_mask(mask2)\n",
    "# visualization = np.zeros((*(aux.shape), 3))\n",
    "# visualization[:, :, 0] = aux\n",
    "# visualization[:, :, 1][mask2] = 1\n",
    "# visualization[:, :, 0][mask2] = 1\n",
    "# imshow(visualization)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VISI",
   "language": "python",
   "name": "visillect"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}